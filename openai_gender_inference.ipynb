{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "670c58ae",
   "metadata": {},
   "source": [
    "# Project Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f72a7c9",
   "metadata": {},
   "source": [
    "Run the following modules to set up imports and settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ab8d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requires \"pip install openai\" on device\n",
    "#!pip install openai\n",
    "import openai\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# Imports for exponential backoff\n",
    "from tenacity import (\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_random_exponential,\n",
    ")  # for exponential backoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d02b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please remove this before committing to a repo.\n",
    "%set_env OPENAI_API_KEY=your_api_key_here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bac122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update this environment variable to reflect where your OpenAI key is stored\n",
    "openai.api_key = %env OPENAI_API_KEY\n",
    "# Check that the API key is being read.\n",
    "#print(openai.api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3316e007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model and max_tokens\n",
    "model = \"gpt-3.5-turbo\"\n",
    "max_tokens = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e012bb",
   "metadata": {},
   "source": [
    "# ChatGPT Querying"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299457e8",
   "metadata": {},
   "source": [
    "The following modules query ChatGPT with exponential backoff to handle failures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ff687e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Queries OpenAI model with exponential backoff.\n",
    "On a failed attempt, function will sleep for a random amount of time between 1 and 60 seconds before trying again.\n",
    "Max 6 attempts before returning a failure.\n",
    "\"\"\"\n",
    "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
    "def chat_completion_with_backoff(**kwargs):\n",
    "    return openai.ChatCompletion.create(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeacb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_names_openai(input_df: pd.DataFrame, start_index: int, end_index: int, first_name_only: bool, include_country: bool) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Processes the specified entries in input_df by performing a query to ChatGPT using name and country information.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_df : pd.DataFrame\n",
    "        The input DataFrame with entries containing name and country data of athletes.\n",
    "        This process assumes input_df has the following columns:\n",
    "        - First Name: The first name of an athlete\n",
    "        - Last Name: The last name of an athlete\n",
    "        - Team: The name of an athlete's country\n",
    "    start_index : int\n",
    "        The starting index from which to process entries in input_df.\n",
    "    end_index : int\n",
    "        The index into input_df to stop processing entries (exclusive, does not process the entry at index end_index).\n",
    "    first_name_only: bool\n",
    "        When true, this function will query using an entry's first name only. Otherwise, will query using an entry's full name.\n",
    "    include_country: bool\n",
    "        When true, this function will query with an entry's country information. Otherwise, will query using only an entry's name.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Returns a dataframe containing the results of the queries to ChatGPT.\n",
    "        The dataframe will have the following columns:\n",
    "        - Index: Stores the index of the associated entry in input_df\n",
    "        - Name: Stores the first or full name used in the query\n",
    "        - Country (Only if include_country == True): Stores the country information used in the query\n",
    "        - Output: The output from the query to ChatGPT\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    # Timestamp for profiling\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Result of each query will be stored in a list before conversion to DataFrame\n",
    "    results_list = []\n",
    "\n",
    "    for i in range(start_index, end_index):\n",
    "        # Get name information for query\n",
    "        if first_name_only:\n",
    "            name = str(input_df.loc[i, 'First Name']).title()\n",
    "        else:\n",
    "            name = str(input_df.loc[i, 'First Name']).title() + \" \" + str(input_df.loc[i, 'Last Name']).title()\n",
    "    \n",
    "        # Get country information for query\n",
    "        if include_country:\n",
    "            country = str(input_df.loc[i, 'Team']).split('-')[0].title()\n",
    "    \n",
    "        # Build the query string\n",
    "        if include_country:\n",
    "            prompt = \"\"\"\n",
    "            I need to pick up someone from {0} named {1}. Am I more likely looking for a male or a female? Report only \"Male\" or \"Female\", and a score from 0 to 1 on how certain you are.  Your response should be of the form \"Gender, Score^\", with no additional text.\n",
    "            \"\"\".format(country, name)\n",
    "        else:\n",
    "            prompt = \"\"\"\n",
    "            I need to pick up someone named {0}. Am I more likely looking for a male or a female? Report only \"Male\" or \"Female\", and a score from 0 to 1 on how certain you are.  Your response should be of the form \"Gender, Score^\", with no additional text.\n",
    "            \"\"\".format(name)\n",
    "    \n",
    "        # Perform query\n",
    "        response = chat_completion_with_backoff(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "        _response = response.choices[0].message.content\n",
    "    \n",
    "        # Store results\n",
    "        if include_country:\n",
    "            results_list.append([i, name, country, _response])\n",
    "        else:\n",
    "            results_list.append([i, name, _response])\n",
    "        \n",
    "        # Some debug statements to track progress\n",
    "        if i % 100 == 0:\n",
    "            print(\"Reached index {0} after {1} seconds.\".format(i, time.time() - start_time))\n",
    "            print(_response)\n",
    "\n",
    "    # Write to DataFrame\n",
    "    if include_country:\n",
    "        output_df = pd.DataFrame(results_list, columns=['index', 'name', 'country', 'output'])\n",
    "    else:\n",
    "        output_df = pd.DataFrame(results_list, columns=['index', 'name', 'output'])\n",
    "        \n",
    "    print(\"Execution time: %s seconds\" % round((time.time() - start_time), 3), \"\\n\")\n",
    "    return output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6575a0",
   "metadata": {},
   "source": [
    "Edit the following arguments before running the query process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874e3a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_name_only = True\n",
    "include_country = False\n",
    "start_index = 80000\n",
    "end_index = 100000\n",
    "\n",
    "input_df_filepath = os.getcwd() + r'/Data/olympic_output.csv'\n",
    "output_df_filepath = os.getcwd() + r'/Data/Prompt2/full_name_country/infer_output_{0}_to_{1}.csv'.format(start_index, end_index - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84489c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Loads the input DataFrame, performs the relevant queries to ChatGPT, and saves the output to a CSV file.\n",
    "\"\"\"\n",
    "input_df = pd.read_csv(input_df_filepath, usecols=['First Name', 'Last Name', 'Team'])\n",
    "output_df = infer_names_openai(olympic_df, start_index, end_index, first_name_only, include_country)\n",
    "output_df.to_csv(output_df_filepath, index=False, header=True, encoding='utf-8-sig')\n",
    "print('Saved output CSV file.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22df801b",
   "metadata": {},
   "source": [
    "# Processing ChatGPT Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0caf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gender_from_raw_output(raw_output: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts the inferred gender from a raw ChatGPT output.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    raw_output : str\n",
    "        The raw output from ChatGPT. Must contain \"Male\" or \"Female\" in the string for a gender to be recognized by this function.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Returns one of the following characters:\n",
    "        - 'F': Female\n",
    "        - 'M': Male\n",
    "        - 'U': Unknown\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    raw_output = raw_output.title()\n",
    "    \n",
    "    female_found = output.find('Female') != -1\n",
    "    male_found = output.find('Male') != -1\n",
    "    \n",
    "    if female_found and male_found:\n",
    "        return 'U'\n",
    "    elif female_found:\n",
    "        return 'F'\n",
    "    elif male_found:\n",
    "        return 'M'\n",
    "    else:\n",
    "        return 'U'\n",
    "    \n",
    "    \n",
    "def get_score_from_raw_output(raw_output: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts the certainty score from a raw ChatGPT output.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    raw_output : str\n",
    "        The raw output from ChatGPT. Must contain a certainty score of the form \"#.#\" to be recognized by this function.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Returns the extracted certainty score if it is recognized, or an empty string.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    score = re.findall(\"\\d+\\.\\d+\", raw_output)\n",
    "    if len(score) > 0:\n",
    "        return score[0]\n",
    "    else:\n",
    "        if output.find('0') != -1:\n",
    "            return '0'\n",
    "        else:\n",
    "            return ''\n",
    "        \n",
    "\n",
    "def process_output(raw_output_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Processes a DataFrame containing the raw output from ChatGPT queries by extracting inferred genders and certainty scores.\n",
    "    This function appends a 'gender'\n",
    "    Rather than returning the results, this function appends a 'gender' and 'score' column to the existing DataFrame, before\n",
    "    saving it back to its original location.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    raw_output_df : pd.DataFrame\n",
    "        A DataFrame containing the raw output from ChatGPT queries. \n",
    "        The output for each entry is assumed to be stored in a 'output' column.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Returns the input DataFrame raw_output_df with additional 'gender' and 'score' columns containing the extracted information.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Parallel lists to hold processed results\n",
    "    genders = []\n",
    "    scores = []\n",
    "    \n",
    "    for i in range(len(raw_output_df)):\n",
    "        raw_output = str(raw_output_df.loc[i, 'output'])\n",
    "        \n",
    "        genders.append(get_gender_from_raw_output(raw_output))\n",
    "        scores.append(get_score_from_raw_output(raw_output))\n",
    "        \n",
    "    # Add new columns to existing df with extracted information\n",
    "    raw_output_df['gender'] = genders\n",
    "    raw_output_df['score'] = scores\n",
    "    \n",
    "    return raw_output_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0278bba6",
   "metadata": {},
   "source": [
    "## Processing - First Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e5d9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_output_df_filepath = os.getcwd() + r'/Data/Prompt2/first_name/olympic_first_name_chatgpt_output_gender_score.csv'\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "raw_output_df = pd.read_csv(raw_output_df_filepath, usecols=['index', 'name', 'output'])\n",
    "raw_output_df = process_output(raw_output_df)\n",
    "raw_output_df.to_csv(raw_output_df_filepath, index=False, header=True, encoding='utf-8-sig')\n",
    "\n",
    "print(\"Execution time: %s seconds\" % round((time.time() - start_time), 3), \"\\n\")\n",
    "print('Finished processing.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf1fb67",
   "metadata": {},
   "source": [
    "## Processing - Full Name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10af6516",
   "metadata": {},
   "source": [
    "## Processing - First Name & Country"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282add9f",
   "metadata": {},
   "source": [
    "## Processing - Full Name & Country"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c5a888",
   "metadata": {},
   "source": [
    "# First Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a810516",
   "metadata": {},
   "outputs": [],
   "source": [
    "olympic_df_0 = pd.read_csv((os.getcwd() + r'/Data/Prompt2/first_name/infer_output_0_to_9999.csv'), usecols=['index', 'name', 'output'])\n",
    "olympic_df_1 = pd.read_csv((os.getcwd() + r'/Data/Prompt2/first_name/infer_output_10000_to_19999.csv'), usecols=['index', 'name', 'output'])\n",
    "olympic_df_2 = pd.read_csv((os.getcwd() + r'/Data/Prompt2/first_name/infer_output_20000_to_25452.csv'), usecols=['index', 'name', 'output'])\n",
    "\n",
    "frames = [olympic_df_0, olympic_df_1, olympic_df_2]\n",
    "result = pd.concat(frames)\n",
    "result.to_csv((os.getcwd() + r'/Data/Prompt2/first_name/infer_output_full.csv'), index=False, header=True, encoding='utf-8-sig')\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ba1dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "olympic_df = pd.read_csv((os.getcwd() + r'/Data/Prompt2/first_name/olympic_first_name_chatgpt_output_gender_score.csv'), usecols=['index', 'name', 'output'])\n",
    "\n",
    "genders = []\n",
    "scores = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(len(olympic_df)):\n",
    "    output = str(olympic_df.loc[i, 'output'])\n",
    "    output = output.title()\n",
    "    \n",
    "    female_found = output.find('Female') != -1\n",
    "    male_found = output.find('Male') != -1\n",
    "    \n",
    "    if female_found and male_found:\n",
    "        genders.append('U')\n",
    "    elif female_found:\n",
    "        genders.append('F')\n",
    "    elif male_found:\n",
    "        genders.append('M')\n",
    "    else:\n",
    "        genders.append('U')\n",
    "        \n",
    "    score = re.findall(\"\\d+\\.\\d+\",output)\n",
    "    if len(score) > 0:\n",
    "        scores.append(score[0])\n",
    "    else:\n",
    "        if output.find('0') != -1:\n",
    "            scores.append('0')\n",
    "        else:\n",
    "            scores.append('')\n",
    "        \n",
    "olympic_df['gender'] = genders\n",
    "olympic_df['score'] = scores\n",
    "olympic_df.to_csv((os.getcwd() + r'/Data/Prompt2/first_name/olympic_first_name_chatgpt_output_gender_score.csv'), index=False, header=True, encoding='utf-8-sig')\n",
    "\n",
    "print(\"Execution time: %s seconds\" % round((time.time() - start_time), 3), \"\\n\")\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d9c8ed",
   "metadata": {},
   "source": [
    "# Full Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800bb119",
   "metadata": {},
   "outputs": [],
   "source": [
    "olympic_df_0 = pd.read_csv((os.getcwd() + r'/Data/Prompt2/full_name/infer_output_0_to_9999.csv'), usecols=['index', 'name', 'output'])\n",
    "olympic_df_1 = pd.read_csv((os.getcwd() + r'/Data/Prompt2/full_name/infer_output_10000_to_19999.csv'), usecols=['index', 'name', 'output'])\n",
    "olympic_df_2 = pd.read_csv((os.getcwd() + r'/Data/Prompt2/full_name/infer_output_20000_to_29999.csv'), usecols=['index', 'name', 'output'])\n",
    "olympic_df_3 = pd.read_csv((os.getcwd() + r'/Data/Prompt2/full_name/infer_output_30000_to_39999.csv'), usecols=['index', 'name', 'output'])\n",
    "olympic_df_4 = pd.read_csv((os.getcwd() + r'/Data/Prompt2/full_name/infer_output_40000_to_49999.csv'), usecols=['index', 'name', 'output'])\n",
    "olympic_df_5 = pd.read_csv((os.getcwd() + r'/Data/Prompt2/full_name/infer_output_50000_to_59999.csv'), usecols=['index', 'name', 'output'])\n",
    "olympic_df_6 = pd.read_csv((os.getcwd() + r'/Data/Prompt2/full_name/infer_output_60000_to_79999.csv'), usecols=['index', 'name', 'output'])\n",
    "olympic_df_7 = pd.read_csv((os.getcwd() + r'/Data/Prompt2/full_name/infer_output_80000_to_89999.csv'), usecols=['index', 'name', 'output'])\n",
    "olympic_df_8 = pd.read_csv((os.getcwd() + r'/Data/Prompt2/full_name/infer_output_90000_to_99999.csv'), usecols=['index', 'name', 'output'])\n",
    "olympic_df_9 = pd.read_csv((os.getcwd() + r'/Data/Prompt2/full_name/infer_output_100000_to_109999.csv'), usecols=['index', 'name', 'output'])\n",
    "olympic_df_10 = pd.read_csv((os.getcwd() + r'/Data/Prompt2/full_name/infer_output_110000_to_119999.csv'), usecols=['index', 'name', 'output'])\n",
    "olympic_df_11 = pd.read_csv((os.getcwd() + r'/Data/Prompt2/full_name/infer_output_120000_to_134731.csv'), usecols=['index', 'name', 'output'])\n",
    "\n",
    "frames = [olympic_df_0, olympic_df_1, olympic_df_2, olympic_df_3, olympic_df_4, olympic_df_5, olympic_df_6, olympic_df_7, olympic_df_8, olympic_df_9, olympic_df_10, olympic_df_11]\n",
    "result = pd.concat(frames)\n",
    "result.to_csv((os.getcwd() + r'/Data/Prompt2/full_name/infer_output_full.csv'), index=False, header=True, encoding='utf-8-sig')\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361e5f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "olympic_df = pd.read_csv((os.getcwd() + r'/Data/Prompt2/full_name/olympic_full_name_chatgpt_output_gender_score.csv'), usecols=['index', 'name', 'output'])\n",
    "\n",
    "genders = []\n",
    "scores = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(len(olympic_df)):\n",
    "    output = str(olympic_df.loc[i, 'output'])\n",
    "    output = output.title()\n",
    "    \n",
    "    female_found = output.find('Female') != -1\n",
    "    male_found = output.find('Male') != -1\n",
    "    \n",
    "    if female_found and male_found:\n",
    "        genders.append('U')\n",
    "    elif female_found:\n",
    "        genders.append('F')\n",
    "    elif male_found:\n",
    "        genders.append('M')\n",
    "    else:\n",
    "        genders.append('U')\n",
    "        \n",
    "    score = re.findall(\"\\d+\\.\\d+\",output)\n",
    "    if len(score) > 0:\n",
    "        scores.append(score[0])\n",
    "    else:\n",
    "        if output.find('0') != -1:\n",
    "            scores.append('0')\n",
    "        else:\n",
    "            scores.append('')\n",
    "        \n",
    "olympic_df['gender'] = genders\n",
    "olympic_df['score'] = scores\n",
    "olympic_df.to_csv((os.getcwd() + r'/Data/Prompt2/full_name/olympic_full_name_chatgpt_output_gender_score.csv'), index=False, header=True, encoding='utf-8-sig')\n",
    "\n",
    "print(\"Execution time: %s seconds\" % round((time.time() - start_time), 3), \"\\n\")\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e1c11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_df = pd.read_csv((os.getcwd() + r'/Data/olympic_output.csv'), usecols=['Sex'])\n",
    "predicted_df = pd.read_csv((os.getcwd() + r'/Data/Prompt2/full_name/olympic_full_name_chatgpt_output_gender_score.csv'), usecols=['gender'])\n",
    "results = {'actual female, predict female': 0, 'actual female, predict male': 0, 'actual female, predict unknown': 0, 'actual male, predict female': 0, 'actual male, predict male': 0, 'actual male, predict unknown': 0}\n",
    "\n",
    "assert len(ground_truth_df) == len(predicted_df)\n",
    "\n",
    "for i in range(len(ground_truth_df)):\n",
    "    ground_truth = ground_truth_df.loc[i, 'Sex']\n",
    "    predicted = predicted_df.loc[i, 'gender']\n",
    "    \n",
    "    if ground_truth == 'F':\n",
    "        if predicted == 'F':\n",
    "            results['actual female, predict female'] += 1\n",
    "        elif predicted == 'M':\n",
    "            results['actual female, predict male'] += 1\n",
    "        elif predicted == 'U':\n",
    "            results['actual female, predict unknown'] += 1\n",
    "    elif ground_truth == 'M':\n",
    "        if predicted == 'F':\n",
    "            results['actual male, predict female'] += 1\n",
    "        elif predicted == 'M':\n",
    "            results['actual male, predict male'] += 1\n",
    "        elif predicted == 'U':\n",
    "            results['actual male, predict unknown'] += 1\n",
    "\n",
    "print(results)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2f9bad",
   "metadata": {},
   "source": [
    "# First Name + Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62a2761",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "olympic_df_0 = pd.read_csv((os.getcwd() + r'/Data/Prompt2/first_name_country/infer_output_0_to_9999.csv'), usecols=['index', 'name', 'country', 'output'])\n",
    "olympic_df_1 = pd.read_csv((os.getcwd() + r'/Data/Prompt2/first_name_country/infer_output_10000_to_19999.csv'), usecols=['index', 'name', 'country', 'output'])\n",
    "olympic_df_2 = pd.read_csv((os.getcwd() + r'/Data/Prompt2/first_name_country/infer_output_20000_to_29999.csv'), usecols=['index', 'name', 'country', 'output'])\n",
    "olympic_df_3 = pd.read_csv((os.getcwd() + r'/Data/Prompt2/first_name_country/infer_output_30000_to_39999.csv'), usecols=['index', 'name', 'country', 'output'])\n",
    "olympic_df_4 = pd.read_csv((os.getcwd() + r'/Data/Prompt2/first_name_country/infer_output_40000_to_51089.csv'), usecols=['index', 'name', 'country', 'output'])\n",
    "\n",
    "frames = [olympic_df_0, olympic_df_1, olympic_df_2, olympic_df_3, olympic_df_4]\n",
    "result = pd.concat(frames)\n",
    "result.to_csv((os.getcwd() + r'/Data/Prompt2/first_name_country/infer_output_full.csv'), index=False, header=True, encoding='utf-8-sig')\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04d0b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "olympic_df = pd.read_csv((os.getcwd() + r'/Data/Prompt2/first_name_country/olympic_first_name_country_chatgpt_output_gender_score.csv'), usecols=['index', 'name', 'output'])\n",
    "\n",
    "genders = []\n",
    "scores = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(len(olympic_df)):\n",
    "    output = str(olympic_df.loc[i, 'output'])\n",
    "    output = output.title()\n",
    "    \n",
    "    female_found = output.find('Female') != -1\n",
    "    male_found = output.find('Male') != -1\n",
    "    \n",
    "    if female_found and male_found:\n",
    "        genders.append('U')\n",
    "    elif female_found:\n",
    "        genders.append('F')\n",
    "    elif male_found:\n",
    "        genders.append('M')\n",
    "    else:\n",
    "        genders.append('U')\n",
    "        \n",
    "    score = re.findall(\"\\d+\\.\\d+\",output)\n",
    "    if len(score) > 0:\n",
    "        scores.append(score[0])\n",
    "    else:\n",
    "        if output.find('0') != -1:\n",
    "            scores.append('0')\n",
    "        else:\n",
    "            scores.append('')\n",
    "        \n",
    "olympic_df['gender'] = genders\n",
    "olympic_df['score'] = scores\n",
    "olympic_df.to_csv((os.getcwd() + r'/Data/Prompt2/first_name_country/olympic_first_name_country_chatgpt_output_gender_score.csv'), index=False, header=True, encoding='utf-8-sig')\n",
    "\n",
    "print(\"Execution time: %s seconds\" % round((time.time() - start_time), 3), \"\\n\")\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862c7311",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_df = pd.read_csv((os.getcwd() + r'/Data/first_name_country/olympic_first_names_actual_gender.csv'), usecols=['gender'])\n",
    "predicted_df = pd.read_csv((os.getcwd() + r'/Data/Prompt2/first_name_country/olympic_first_name_country_chatgpt_output_gender_score.csv'), usecols=['gender'])\n",
    "\n",
    "results = {'actual female, predict female': 0, \n",
    "           'actual female, predict male': 0, \n",
    "           'actual female, predict unknown': 0, \n",
    "           'actual male, predict female': 0, \n",
    "           'actual male, predict male': 0, \n",
    "           'actual male, predict unknown': 0,\n",
    "           'actual unknown, predict female': 0,\n",
    "           'actual unknown, predict male': 0,\n",
    "           'actual unknown, predict unknown': 0}\n",
    "\n",
    "\n",
    "for i in range(len(df)):\n",
    "    gender = df.loc[i, 'gender']\n",
    "    predicted = df.loc[i, 'predicted_gender']\n",
    "    df.loc[df['column_name'] == some_value]\n",
    "    \n",
    "    if gender == 'F':\n",
    "        if predicted == 'F':\n",
    "            results['actual female, predict female'] += 1\n",
    "        elif predicted == 'M':\n",
    "            results['actual female, predict male'] += 1\n",
    "        elif predicted == 'U':\n",
    "            results['actual female, predict unknown'] += 1\n",
    "    elif gender == 'M':\n",
    "        if predicted == 'F':\n",
    "            results['actual male, predict female'] += 1\n",
    "        elif predicted == 'M':\n",
    "            results['actual male, predict male'] += 1\n",
    "        elif predicted == 'U':\n",
    "            results['actual male, predict unknown'] += 1\n",
    "    elif gender == 'U':\n",
    "        if predicted == 'F':\n",
    "            results['actual unknown, predict female'] += 1\n",
    "        elif predicted == 'M':\n",
    "            results['actual unknown, predict male'] += 1\n",
    "        elif predicted == 'U':\n",
    "            results['actual unknown, predict unknown'] += 1\n",
    "            \n",
    "print(results)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5caf4a17",
   "metadata": {},
   "source": [
    "# Full Name + Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63abb40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "olympic_df_0 = pd.read_csv((os.getcwd() + r'/Data/Prompt2/full_name_country/infer_output_0_to_9999.csv'), usecols=['index', 'name', 'country', 'output'])\n",
    "olympic_df_1 = pd.read_csv((os.getcwd() + r'/Data/Prompt2/full_name_country/infer_output_10000_to_39999.csv'), usecols=['index', 'name', 'country', 'output'])\n",
    "olympic_df_2 = pd.read_csv((os.getcwd() + r'/Data/Prompt2/full_name_country/infer_output_40000_to_59999.csv'), usecols=['index', 'name', 'country', 'output'])\n",
    "olympic_df_3 = pd.read_csv((os.getcwd() + r'/Data/Prompt2/full_name_country/infer_output_60000_to_89999.csv'), usecols=['index', 'name', 'country', 'output'])\n",
    "olympic_df_4 = pd.read_csv((os.getcwd() + r'/Data/Prompt2/full_name_country/infer_output_90000_to_109999.csv'), usecols=['index', 'name', 'country', 'output'])\n",
    "olympic_df_5 = pd.read_csv((os.getcwd() + r'/Data/Prompt2/full_name_country/infer_output_110000_to_124999.csv'), usecols=['index', 'name', 'country', 'output'])\n",
    "olympic_df_6 = pd.read_csv((os.getcwd() + r'/Data/Prompt2/full_name_country/infer_output_125000_to_134731.csv'), usecols=['index', 'name', 'country', 'output'])\n",
    "\n",
    "frames = [olympic_df_0, olympic_df_1, olympic_df_2, olympic_df_3, olympic_df_4, olympic_df_5, olympic_df_6]\n",
    "result = pd.concat(frames)\n",
    "result.to_csv((os.getcwd() + r'/Data/Prompt2/full_name_country/infer_output_full.csv'), index=False, header=True, encoding='utf-8-sig')\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd51f757",
   "metadata": {},
   "outputs": [],
   "source": [
    "olympic_df = pd.read_csv((os.getcwd() + r'/Data/Prompt2/full_name_country/olympic_full_name_country_chatgpt_output_gender_score.csv'), usecols=['index', 'name', 'output'])\n",
    "\n",
    "genders = []\n",
    "scores = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(len(olympic_df)):\n",
    "    output = str(olympic_df.loc[i, 'output'])\n",
    "    output = output.title()\n",
    "    \n",
    "    female_found = output.find('Female') != -1\n",
    "    male_found = output.find('Male') != -1\n",
    "    \n",
    "    if female_found and male_found:\n",
    "        genders.append('U')\n",
    "    elif female_found:\n",
    "        genders.append('F')\n",
    "    elif male_found:\n",
    "        genders.append('M')\n",
    "    else:\n",
    "        genders.append('U')\n",
    "        \n",
    "    score = re.findall(\"\\d+\\.\\d+\",output)\n",
    "    if len(score) > 0:\n",
    "        scores.append(score[0])\n",
    "    else:\n",
    "        if output.find('0') != -1:\n",
    "            scores.append('0')\n",
    "        else:\n",
    "            scores.append('')\n",
    "        \n",
    "olympic_df['gender'] = genders\n",
    "olympic_df['score'] = scores\n",
    "olympic_df.to_csv((os.getcwd() + r'/Data/Prompt2/full_name_country/olympic_full_name_country_chatgpt_output_gender_score.csv'), index=False, header=True, encoding='utf-8-sig')\n",
    "\n",
    "print(\"Execution time: %s seconds\" % round((time.time() - start_time), 3), \"\\n\")\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1530f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_df = pd.read_csv((os.getcwd() + r'/Data/olympic_output.csv'), usecols=['Sex'])\n",
    "predicted_df = pd.read_csv((os.getcwd() + r'/Data/Prompt2/full_name_country/olympic_full_name_country_chatgpt_output_gender_score.csv'), usecols=['gender'])\n",
    "results = {'actual female, predict female': 0, 'actual female, predict male': 0, 'actual female, predict unknown': 0, 'actual male, predict female': 0, 'actual male, predict male': 0, 'actual male, predict unknown': 0}\n",
    "\n",
    "assert len(ground_truth_df) == len(predicted_df)\n",
    "\n",
    "for i in range(len(ground_truth_df)):\n",
    "    ground_truth = ground_truth_df.loc[i, 'Sex']\n",
    "    predicted = predicted_df.loc[i, 'gender']\n",
    "    \n",
    "    if ground_truth == 'F':\n",
    "        if predicted == 'F':\n",
    "            results['actual female, predict female'] += 1\n",
    "        elif predicted == 'M':\n",
    "            results['actual female, predict male'] += 1\n",
    "        elif predicted == 'U':\n",
    "            results['actual female, predict unknown'] += 1\n",
    "    elif ground_truth == 'M':\n",
    "        if predicted == 'F':\n",
    "            results['actual male, predict female'] += 1\n",
    "        elif predicted == 'M':\n",
    "            results['actual male, predict male'] += 1\n",
    "        elif predicted == 'U':\n",
    "            results['actual male, predict unknown'] += 1\n",
    "\n",
    "print(results)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758e2e2d",
   "metadata": {},
   "source": [
    "## Data Parsing And Cleaning (OUTDATED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6424c241",
   "metadata": {},
   "outputs": [],
   "source": [
    "olympic_df_0 = pd.read_csv((os.getcwd() + r'\\Data\\full_name\\infer_output_0_to_9999.csv'), usecols=['index', 'full_name', 'output'])\n",
    "olympic_df_1 = pd.read_csv((os.getcwd() + r'\\Data\\full_name\\infer_output_10000_to_19999.csv'), usecols=['index', 'full_name', 'output'])\n",
    "olympic_df_2 = pd.read_csv((os.getcwd() + r'\\Data\\full_name\\infer_output_20000_to_49999.csv'), usecols=['index', 'full_name', 'output'])\n",
    "olympic_df_3 = pd.read_csv((os.getcwd() + r'\\Data\\full_name\\infer_output_50000_to_79999.csv'), usecols=['index', 'full_name', 'output'])\n",
    "olympic_df_4 = pd.read_csv((os.getcwd() + r'\\Data\\full_name\\infer_output_80000_to_89999.csv'), usecols=['index', 'full_name', 'output'])\n",
    "olympic_df_5 = pd.read_csv((os.getcwd() + r'\\Data\\full_name\\infer_output_90000_to_109999.csv'), usecols=['index', 'full_name', 'output'])\n",
    "olympic_df_6 = pd.read_csv((os.getcwd() + r'\\Data\\full_name\\infer_output_110000_to_134699.csv'), usecols=['index', 'full_name', 'output'])\n",
    "olympic_df_7 = pd.read_csv((os.getcwd() + r'\\Data\\full_name\\infer_output_134700_to_134731.csv'), usecols=['index', 'full_name', 'output'])\n",
    "\n",
    "frames = [olympic_df_0, olympic_df_1, olympic_df_2, olympic_df_3, olympic_df_4, olympic_df_5, olympic_df_6, olympic_df_7]\n",
    "result = pd.concat(frames)\n",
    "result.to_csv((os.getcwd() + r'\\Data\\full_name\\infer_output_full.csv'), index=False, header=True, encoding='utf-8-sig')\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127a08f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "olympic_df_0 = pd.read_csv((os.getcwd() + r'\\Data\\full_name_country\\infer_output_0_to_9999.csv'), usecols=['index', 'full_name', 'output'])\n",
    "olympic_df_1 = pd.read_csv((os.getcwd() + r'\\Data\\full_name_country\\infer_output_10000_to_29999.csv'), usecols=['index', 'full_name', 'output'])\n",
    "olympic_df_2 = pd.read_csv((os.getcwd() + r'\\Data\\full_name_country\\infer_output_30000_to_39999.csv'), usecols=['index', 'full_name', 'output'])\n",
    "olympic_df_3 = pd.read_csv((os.getcwd() + r'\\Data\\full_name_country\\infer_output_40000_to_49999.csv'), usecols=['index', 'full_name', 'output'])\n",
    "olympic_df_4 = pd.read_csv((os.getcwd() + r'\\Data\\full_name_country\\infer_output_50000_to_59999.csv'), usecols=['index', 'full_name', 'output'])\n",
    "olympic_df_5 = pd.read_csv((os.getcwd() + r'\\Data\\full_name_country\\infer_output_60000_to_69999.csv'), usecols=['index', 'full_name', 'output'])\n",
    "olympic_df_6 = pd.read_csv((os.getcwd() + r'\\Data\\full_name_country\\infer_output_70000_to_79999.csv'), usecols=['index', 'full_name', 'output'])\n",
    "olympic_df_7 = pd.read_csv((os.getcwd() + r'\\Data\\full_name_country\\infer_output_80000_to_89999.csv'), usecols=['index', 'full_name', 'output'])\n",
    "olympic_df_8 = pd.read_csv((os.getcwd() + r'\\Data\\full_name_country\\infer_output_90000_to_109999.csv'), usecols=['index', 'full_name', 'output'])\n",
    "olympic_df_9 = pd.read_csv((os.getcwd() + r'\\Data\\full_name_country\\infer_output_110000_to_129999.csv'), usecols=['index', 'full_name', 'output'])\n",
    "olympic_df_10 = pd.read_csv((os.getcwd() + r'\\Data\\full_name_country\\infer_output_130000_to_134731.csv'), usecols=['index', 'full_name', 'output'])\n",
    "\n",
    "frames = [olympic_df_0, olympic_df_1, olympic_df_2, olympic_df_3, olympic_df_4, olympic_df_5, olympic_df_6, olympic_df_7, olympic_df_8, olympic_df_9, olympic_df_10]\n",
    "result = pd.concat(frames)\n",
    "result.to_csv((os.getcwd() + r'\\Data\\full_name_country\\olympic_full_names_country_chatgpt_output_gender_score.csv'), index=False, header=True, encoding='utf-8-sig')\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5e25c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "olympic_df = pd.read_csv((os.getcwd() + r'\\Data\\full_name_country\\olympic_full_names_country_chatgpt_output_gender_score.csv'), usecols=['index', 'full_name', 'output'])\n",
    "\n",
    "genders = []\n",
    "scores = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(len(olympic_df)):\n",
    "    if i % 1000 == 0:\n",
    "        print(\"Reached index {0} after {1} seconds.\".format(i, time.time() - start_time))\n",
    "    \n",
    "    output = str(olympic_df.loc[i, 'output'])\n",
    "    output = output.title()\n",
    "    \n",
    "    female_found = output.find('Female') != -1\n",
    "    male_found = output.find('Male') != -1\n",
    "    \n",
    "    if female_found and male_found:\n",
    "        genders.append('U')\n",
    "    elif female_found:\n",
    "        genders.append('F')\n",
    "    elif male_found:\n",
    "        genders.append('M')\n",
    "    else:\n",
    "        genders.append('U')\n",
    "        \n",
    "    score = re.findall(\"\\d+\\.\\d+\",output)\n",
    "    if len(score) > 0:\n",
    "        scores.append(score[0])\n",
    "    else:\n",
    "        if output.find('0') != -1:\n",
    "            scores.append('0')\n",
    "        else:\n",
    "            scores.append('')\n",
    "        \n",
    "olympic_df['gender'] = genders\n",
    "olympic_df['score'] = scores\n",
    "olympic_df.to_csv((os.getcwd() + r'\\Data\\full_name_country\\olympic_full_names_country_chatgpt_output_gender_score.csv'), index=False, header=True, encoding='utf-8-sig')\n",
    "\n",
    "print(\"Execution time: %s seconds\" % round((time.time() - start_time), 3), \"\\n\")\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903ef4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_df = pd.read_csv((os.getcwd() + r'\\Data\\olympic_output.csv'), usecols=['Sex'])\n",
    "predicted_df = pd.read_csv((os.getcwd() + r'\\Data\\full_name\\olympic_full_names_chatgpt_output_gender_score.csv'), usecols=['gender'])\n",
    "results = {'actual female, predict female': 0, 'actual female, predict male': 0, 'actual female, predict unknown': 0, 'actual male, predict female': 0, 'actual male, predict male': 0, 'actual male, predict unknown': 0}\n",
    "\n",
    "assert len(ground_truth_df) == len(predicted_df)\n",
    "\n",
    "for i in range(len(ground_truth_df)):\n",
    "    ground_truth = ground_truth_df.loc[i, 'Sex']\n",
    "    predicted = predicted_df.loc[i, 'gender']\n",
    "    \n",
    "    if ground_truth == 'F':\n",
    "        if predicted == 'F':\n",
    "            results['actual female, predict female'] += 1\n",
    "        elif predicted == 'M':\n",
    "            results['actual female, predict male'] += 1\n",
    "        elif predicted == 'U':\n",
    "            results['actual female, predict unknown'] += 1\n",
    "    elif ground_truth == 'M':\n",
    "        if predicted == 'F':\n",
    "            results['actual male, predict female'] += 1\n",
    "        elif predicted == 'M':\n",
    "            results['actual male, predict male'] += 1\n",
    "        elif predicted == 'U':\n",
    "            results['actual male, predict unknown'] += 1\n",
    "\n",
    "print(results)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af0775e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_df = pd.read_csv((os.getcwd() + r'\\Data\\olympic_output.csv'), usecols=['Sex', 'Medal'])\n",
    "predicted_df = pd.read_csv((os.getcwd() + r'\\Data\\full_name\\olympic_full_names_chatgpt_output_gender_score.csv'), usecols=['gender'])\n",
    "results = {'no medal, correct prediction': 0, 'no medal, incorrect prediction': 0, 'bronze medal, correct prediction': 0, 'bronze medal, incorrect prediction': 0, 'silver medal, correct prediction': 0, 'silver medal, incorrect prediction': 0, 'gold medal, correct prediction': 0, 'gold medal, incorrect prediction': 0}\n",
    "\n",
    "assert len(ground_truth_df) == len(predicted_df)\n",
    "\n",
    "for i in range(len(ground_truth_df)):\n",
    "    ground_truth = ground_truth_df.loc[i, 'Sex']\n",
    "    medal = ground_truth_df.loc[i, 'Medal']\n",
    "    predicted = predicted_df.loc[i, 'gender']\n",
    "    \n",
    "    if pd.isna(medal):\n",
    "        if ground_truth == predicted:\n",
    "            results['no medal, correct prediction'] += 1\n",
    "        else:\n",
    "            results['no medal, incorrect prediction'] += 1\n",
    "    elif medal == 'Bronze':\n",
    "        if ground_truth == predicted:\n",
    "            results['bronze medal, correct prediction'] += 1\n",
    "        else:\n",
    "            results['bronze medal, incorrect prediction'] += 1\n",
    "    elif medal == 'Silver':\n",
    "        if ground_truth == predicted:\n",
    "            results['silver medal, correct prediction'] += 1\n",
    "        else:\n",
    "            results['silver medal, incorrect prediction'] += 1\n",
    "    elif medal == 'Gold':\n",
    "        if ground_truth == predicted:\n",
    "            results['gold medal, correct prediction'] += 1\n",
    "        else:\n",
    "            results['gold medal, incorrect prediction'] += 1\n",
    "\n",
    "print(results)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d4763a",
   "metadata": {},
   "source": [
    "## First Names Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e697ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv((os.getcwd() + r'/Data/first_name/olympic_first_names_final.csv'), usecols=['gender', 'predicted_gender'])\n",
    "\n",
    "results = {'actual female, predict female': 0, \n",
    "           'actual female, predict male': 0, \n",
    "           'actual female, predict unknown': 0, \n",
    "           'actual male, predict female': 0, \n",
    "           'actual male, predict male': 0, \n",
    "           'actual male, predict unknown': 0,\n",
    "           'actual unknown, predict female': 0,\n",
    "           'actual unknown, predict male': 0,\n",
    "           'actual unknown, predict unknown': 0}\n",
    "\n",
    "\n",
    "for i in range(len(df)):\n",
    "    gender = df.loc[i, 'gender']\n",
    "    predicted = df.loc[i, 'predicted_gender']\n",
    "    \n",
    "    if gender == 'F':\n",
    "        if predicted == 'F':\n",
    "            results['actual female, predict female'] += 1\n",
    "        elif predicted == 'M':\n",
    "            results['actual female, predict male'] += 1\n",
    "        elif predicted == 'U':\n",
    "            results['actual female, predict unknown'] += 1\n",
    "    elif gender == 'M':\n",
    "        if predicted == 'F':\n",
    "            results['actual male, predict female'] += 1\n",
    "        elif predicted == 'M':\n",
    "            results['actual male, predict male'] += 1\n",
    "        elif predicted == 'U':\n",
    "            results['actual male, predict unknown'] += 1\n",
    "    elif gender == 'U':\n",
    "        if predicted == 'F':\n",
    "            results['actual unknown, predict female'] += 1\n",
    "        elif predicted == 'M':\n",
    "            results['actual unknown, predict male'] += 1\n",
    "        elif predicted == 'U':\n",
    "            results['actual unknown, predict unknown'] += 1\n",
    "            \n",
    "print(results)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c238bf",
   "metadata": {},
   "source": [
    "## First Names + Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6886b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv((os.getcwd() + r'/Data/first_name_country/olympic_first_names_country_final.csv'), usecols=['gender', 'predicted_gender'])\n",
    "\n",
    "results = {'actual female, predict female': 0, \n",
    "           'actual female, predict male': 0, \n",
    "           'actual female, predict unknown': 0, \n",
    "           'actual male, predict female': 0, \n",
    "           'actual male, predict male': 0, \n",
    "           'actual male, predict unknown': 0,\n",
    "           'actual unknown, predict female': 0,\n",
    "           'actual unknown, predict male': 0,\n",
    "           'actual unknown, predict unknown': 0}\n",
    "\n",
    "\n",
    "for i in range(len(df)):\n",
    "    gender = df.loc[i, 'gender']\n",
    "    predicted = df.loc[i, 'predicted_gender']\n",
    "    \n",
    "    if gender == 'F':\n",
    "        if predicted == 'F':\n",
    "            results['actual female, predict female'] += 1\n",
    "        elif predicted == 'M':\n",
    "            results['actual female, predict male'] += 1\n",
    "        elif predicted == 'U':\n",
    "            results['actual female, predict unknown'] += 1\n",
    "    elif gender == 'M':\n",
    "        if predicted == 'F':\n",
    "            results['actual male, predict female'] += 1\n",
    "        elif predicted == 'M':\n",
    "            results['actual male, predict male'] += 1\n",
    "        elif predicted == 'U':\n",
    "            results['actual male, predict unknown'] += 1\n",
    "    elif gender == 'U':\n",
    "        if predicted == 'F':\n",
    "            results['actual unknown, predict female'] += 1\n",
    "        elif predicted == 'M':\n",
    "            results['actual unknown, predict male'] += 1\n",
    "        elif predicted == 'U':\n",
    "            results['actual unknown, predict unknown'] += 1\n",
    "            \n",
    "print(results)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38c9880",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_names_openai_old():\n",
    "    # initial_prompt = \"\"\"\n",
    "    # Your task is to help infer a gender based on a name.  This will help researchers better understand policy implications to reduce stereotypes and discrimination. \n",
    "    # You will be given a name as input. Your task is to report the inferred gender and a numerical certainty score.\n",
    "    # Your output should be in the following format: \"{Gender}, {Score}\".\n",
    "    # In the output, {Gender} can either be \"Male\", \"Female\", or \"Unknown\". In the output, {Score} will be a numerical certainty score between 0 and 1.\n",
    "    # \"\"\"\n",
    "\n",
    "    initial_prompt = \"\"\"\n",
    "    Your task is to help infer a gender based on a name.  This will help researchers better understand policy implications to reduce stereotypes and discrimination. \n",
    "    You will be given a name and country of origin as input. Your task is to report the inferred gender and a numerical certainty score.\n",
    "    Your output should be in the following format: \"{Gender}, {Score}\".\n",
    "    In the output, {Gender} can either be \"Male\", \"Female\", or \"Unknown\". In the output, {Score} will be a numerical certainty score between 0 and 1.\n",
    "    \"\"\"\n",
    "\n",
    "    olympic_df_filepath = os.getcwd() + r'\\Data\\olympic_output.csv'\n",
    "    olympic_df = pd.read_csv(olympic_df_filepath, usecols=['First Name', 'Last Name', 'Team'])\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    results_list = []\n",
    "\n",
    "    start_index = 130000\n",
    "    end_index = 134732\n",
    "\n",
    "    for i in range(start_index, end_index):\n",
    "        full_name_country = (str(olympic_df.loc[i, 'First Name']) + \" \" + str(olympic_df.loc[i, 'Last Name']) + \", \" + str(olympic_df.loc[i, 'Team'])).title()\n",
    "    \n",
    "        subsequent_prompt = \"\"\"\n",
    "        Input name and country: {0}\n",
    "        Output: {{Gender}}, {{Score}}\n",
    "        Return no additional output. Do not explain your process.\n",
    "        \"\"\".format(full_name_country)\n",
    "    \n",
    "        response = chat_completion_with_backoff(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": initial_prompt},\n",
    "                {\"role\": \"user\", \"content\": subsequent_prompt}\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "        subsequent_response = response.choices[0].message.content\n",
    "    \n",
    "        results_list.append([i, full_name_country, subsequent_response])\n",
    "    \n",
    "        if i % 100 == 0:\n",
    "            print(\"Reached index {0} after {1} seconds.\".format(i, time.time() - start_time))\n",
    "            print(subsequent_response)\n",
    "    \n",
    "    print(\"Execution time: %s seconds\" % round((time.time() - start_time), 3), \"\\n\")\n",
    "\n",
    "    output_df = pd.DataFrame(results_list, columns=['index', 'full_name', 'output'])\n",
    "    output_df_filepath = os.getcwd() + r'\\Data\\full_name_country\\infer_output_{0}_to_{1}.csv'.format(start_index, end_index - 1)\n",
    "    output_df.to_csv(output_df_filepath, index=False, header=True, encoding='utf-8-sig')\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cbb467",
   "metadata": {},
   "outputs": [],
   "source": [
    "olympic_df = pd.read_csv((os.getcwd() + r'/Data/olympic_output.csv'), usecols=['First Name', 'Last Name', 'Team', 'Sex'])\n",
    "first_name_df = pd.read_csv((os.getcwd() + r'/Data/Prompt2/first_name/olympic_first_name_chatgpt_output_gender_score.csv'), usecols=['name', 'gender'])\n",
    "full_name_df = pd.read_csv((os.getcwd() + r'/Data/Prompt2/full_name/olympic_full_name_chatgpt_output_gender_score.csv'), usecols=['name', 'gender'])\n",
    "first_name_country_df = pd.read_csv((os.getcwd() + r'/Data/Prompt2/first_name_country/olympic_first_name_country_chatgpt_output_gender_score.csv'), usecols=['name', 'gender'])\n",
    "full_name_country_df = pd.read_csv((os.getcwd() + r'/Data/Prompt2/full_name_country/olympic_full_name_country_chatgpt_output_gender_score.csv'), usecols=['name', 'gender'])\n",
    "\n",
    "results_list = []\n",
    "\n",
    "for i in range(len(olympic_df)):\n",
    "    first_name = str(olympic_df.loc[i, 'First Name']).title()\n",
    "    full_name = str(olympic_df.loc[i, 'First Name']).title() + \" \" + str(olympic_df.loc[i, 'Last Name']).title()\n",
    "    country = str(olympic_df.loc[i, 'Team']).split('-')[0].title()\n",
    "    actual_sex = str(olympic_df.loc[i, 'Sex'])\n",
    "    \n",
    "    # Use index to compare, assert that names are the same\n",
    "    first_name_gender = ''\n",
    "    first_name_score = ''\n",
    "    full_name_gender = ''\n",
    "    full_name_score = ''\n",
    "    first_name_country_gender = ''\n",
    "    first_name_country_score = ''\n",
    "    full_name_country_gender = ''\n",
    "    full_name_country_score = ''\n",
    "    \n",
    "    # Index, Full Name, Country, Sex, First-Name Gender + Score, Full-Name Gender + Score, First-Name-Country Gender + Score, Full-Name-Country Gender + Score\n",
    "    results_list.append([i, full_name, country, actual_sex, first_name_gender, first_name_score, full_name_gender, full_name_score, first_name_country_gender, first_name_country_score, full_name_country_gender, full_name_country_score])\n",
    "    \n",
    "output_df = pd.DataFrame(results_list, columns=['index', 'name', 'country', 'sex', 'first_name_gender', 'first_name_score' 'full_name_gender', 'full_name_score', 'first_name_country_gender', 'first_name_country_score', 'full_name_country_gender', 'full_name_country_score'])\n",
    "output_df.to_csv((os.getcwd() + r'/Data/Prompt2/final_results.csv'), index=False, header=True, encoding='utf-8-sig')\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a32f25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
