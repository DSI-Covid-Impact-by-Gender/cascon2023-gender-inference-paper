{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "670c58ae",
   "metadata": {},
   "source": [
    "# Project Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f72a7c9",
   "metadata": {},
   "source": [
    "Run the following modules to set up imports and settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ab8d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requires \"pip install openai\" on device\n",
    "#!pip install openai\n",
    "import openai\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "# Imports for exponential backoff\n",
    "from tenacity import (\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_random_exponential,\n",
    ")  # for exponential backoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d02b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please remove this before committing to a repo.\n",
    "%set_env OPENAI_API_KEY=your_api_key_here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bac122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update this environment variable to reflect where your OpenAI key is stored\n",
    "openai.api_key = %env OPENAI_API_KEY\n",
    "# Check that the API key is being read.\n",
    "#print(openai.api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3316e007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model and max_tokens\n",
    "model = \"gpt-3.5-turbo\"\n",
    "max_tokens = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da27296",
   "metadata": {},
   "source": [
    "# Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d25d34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Root Folder Filepath ----------\n",
    "\n",
    "root_folder_filepath = os.getcwd() + r'/data/'\n",
    "\n",
    "# ---------- Source Dataset CSV Columns ----------\n",
    "\n",
    "source_forename_col = \"First Name\"\n",
    "source_surname_col = \"Last Name\"\n",
    "source_country_col = \"Team\" # Using team column to avoid having to parse country codes\n",
    "source_sex_col = \"Sex\"\n",
    "source_medal_col = \"Medal\"\n",
    "\n",
    "# ---------- Query Result CSV Columns ----------\n",
    "\n",
    "index_col = \"index\"\n",
    "name_col = \"name\"\n",
    "country_col = \"country\"\n",
    "output_col = \"output\"\n",
    "gender_col = \"gender\"\n",
    "score_col = \"score\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e012bb",
   "metadata": {},
   "source": [
    "# ChatGPT Querying"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299457e8",
   "metadata": {},
   "source": [
    "The following modules query ChatGPT with exponential backoff to handle failures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ff687e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Queries OpenAI model with exponential backoff.\n",
    "On a failed attempt, function will sleep for a random amount of time between 1 and 60 seconds before trying again.\n",
    "Max 6 attempts before returning a failure.\n",
    "\"\"\"\n",
    "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
    "def chat_completion_with_backoff(**kwargs):\n",
    "    return openai.ChatCompletion.create(**kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16370255",
   "metadata": {},
   "source": [
    "## Query Procedure Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9489c7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gender_from_raw_output(raw_output: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts the inferred gender from a raw ChatGPT output.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    raw_output : str\n",
    "        The raw output from ChatGPT. Must contain \"Male\" or \"Female\" in the string for a gender to be recognized by this function.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Returns one of the following characters:\n",
    "        - 'F': Female\n",
    "        - 'M': Male\n",
    "        - 'U': Unknown\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    raw_output = raw_output.title()\n",
    "    \n",
    "    female_found = output.find('Female') != -1\n",
    "    male_found = output.find('Male') != -1\n",
    "    \n",
    "    if female_found and male_found:\n",
    "        return 'U'\n",
    "    elif female_found:\n",
    "        return 'F'\n",
    "    elif male_found:\n",
    "        return 'M'\n",
    "    else:\n",
    "        return 'U'\n",
    "    \n",
    "    \n",
    "def get_score_from_raw_output(raw_output: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts the certainty score from a raw ChatGPT output.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    raw_output : str\n",
    "        The raw output from ChatGPT. Must contain a certainty score of the form \"#.#\" to be recognized by this function.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Returns the extracted certainty score if it is recognized, or an empty string.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    score = re.findall(\"\\d+\\.\\d+\", raw_output)\n",
    "    if len(score) > 0:\n",
    "        return score[0]\n",
    "    else:\n",
    "        if output.find('0') != -1:\n",
    "            return '0'\n",
    "        else:\n",
    "            return ''\n",
    "        \n",
    "\n",
    "def perform_query(prompt: str, rerun_count: int) -> (str, str, str):\n",
    "    query_count = 0\n",
    "    \n",
    "    while query_count < rerun_count + 1:\n",
    "        # Perform query\n",
    "        response = chat_completion_with_backoff(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Extract inferred gender and certainty score\n",
    "        raw_output = response.choices[0].message.content\n",
    "        gender = get_gender_from_raw_output(raw_output)\n",
    "        score = get_score_from_raw_output(raw_output)\n",
    "        \n",
    "        if gender != \"U\":\n",
    "            return raw_output, gender, score\n",
    "        \n",
    "        query_count += 1\n",
    "        \n",
    "    return raw_output, gender, score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcce1508",
   "metadata": {},
   "source": [
    "## Query Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b643b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_names_openai2(\n",
    "    source_df: pd.DataFrame, \n",
    "    start_index: int, \n",
    "    end_index: int, \n",
    "    first_name_only: bool, \n",
    "    include_country: bool,\n",
    "    rerun_count: int\n",
    ") -> pd.DataFrame:\n",
    "    \n",
    "    # Timestamp for profiling\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Result of each query will be stored in a list before conversion to DataFrame\n",
    "    results_list = []\n",
    "    \n",
    "    for i in range(start_index, end_index):\n",
    "        # Get name information for query\n",
    "        if first_name_only:\n",
    "            name = str(source_df.loc[i, source_forename_col]).title()\n",
    "        else:\n",
    "            name = str(source_df.loc[i, source_forename_col]).title() + \" \" + str(source_df.loc[i, source_surname_col]).title()\n",
    "    \n",
    "        # Get country information for query\n",
    "        if include_country:\n",
    "            country = str(source_df.loc[i, source_country_col]).split('-')[0].title()\n",
    "    \n",
    "        # Build the query string\n",
    "        if include_country:\n",
    "            prompt = \"\"\"\n",
    "            I need to pick up someone from {0} named {1}. Am I more likely looking for a male or a female? Report only \"Male\" or \"Female\", and a score from 0 to 1 on how certain you are.  Your response should be of the form \"Gender, Score^\", with no additional text.\n",
    "            \"\"\".format(country, name)\n",
    "        else:\n",
    "            prompt = \"\"\"\n",
    "            I need to pick up someone named {0}. Am I more likely looking for a male or a female? Report only \"Male\" or \"Female\", and a score from 0 to 1 on how certain you are.  Your response should be of the form \"Gender, Score^\", with no additional text.\n",
    "            \"\"\".format(name)\n",
    "            \n",
    "        # Perform query, rerunning it for unknown responses if required\n",
    "        raw_output, gender, score = perform_query(prompt, rerun_count)\n",
    "    \n",
    "        # Store results\n",
    "        if include_country:\n",
    "            results_list.append([i, name, country, raw_output, gender, score])\n",
    "        else:\n",
    "            results_list.append([i, name, raw_output, gender, score])\n",
    "        \n",
    "        # Some debug statements to track progress\n",
    "        if i % 100 == 0:\n",
    "            print(\"Reached index {0} after {1} seconds.\".format(i, time.time() - start_time))\n",
    "            print(raw_output)\n",
    "            \n",
    "    # Write to DataFrame\n",
    "    if include_country:\n",
    "        output_df = pd.DataFrame(results_list, columns=[index_col, name_col, country_col, output_col, gender_col, score_col])\n",
    "    else:\n",
    "        output_df = pd.DataFrame(results_list, columns=[index_col, name_col, output_col, gender_col, score_col])\n",
    "    \n",
    "    print(\"Execution time: %s seconds\" % round((time.time() - start_time), 3), \"\\n\")\n",
    "    return output_df\n",
    "\n",
    "def infer_names_openai_csv(\n",
    "    source_df_filepath: str,\n",
    "    output_df_filepath: str,\n",
    "    start_index: int, \n",
    "    end_index: int, \n",
    "    first_name_only: bool, \n",
    "    include_country: bool,\n",
    "    rerun_count: int\n",
    ") -> None:\n",
    "    \n",
    "    source_df = pd.read_csv(source_df_filepath, usecols=[source_forename_col, source_surname_col, source_country_col])\n",
    "    output_df = infer_names_openai(source_df, start_index, end_index, first_name_only, include_country, rerun_count)\n",
    "    output_df.to_csv(output_df_filepath, index=False, header=True, encoding='utf-8-sig')\n",
    "    print('Saved output CSV file.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e7107a",
   "metadata": {},
   "source": [
    "## Concatenating CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0e7397",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_csv(csv_filepaths: List[str], cols: List[str], save_filepath) -> None:\n",
    "    \"\"\"\n",
    "    Helper function used to concatenate multiple CSV files into a single file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    csv_filepaths : List[str]\n",
    "        A list of filepaths leading to the CSV files to merge into a single file.\n",
    "    cols : List[str]\n",
    "        A list of column names shared by all CSV files to be loaded.\n",
    "    save_filepath : str\n",
    "        Filepath used to save merged CSV file.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    df_list = []\n",
    "    for filepath in csv_filepaths:\n",
    "        df_list.append(pd.read_csv(filepath, usecols=cols))\n",
    "    \n",
    "    merged_df = pd.concat(df_list)\n",
    "    merged_df.to_csv(save_filepath, index=False, header=True, encoding='utf-8-sig')\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fa4c0f",
   "metadata": {},
   "source": [
    "# Execution "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63fc2463",
   "metadata": {},
   "source": [
    "## First Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455d984a",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index = 0\n",
    "end_index = 10000\n",
    "first_name_only = True\n",
    "include_country = False\n",
    "rerun_count = 0\n",
    "\n",
    "source_df_filepath = root_folder_filepath + r'source_olympic_data.csv'\n",
    "output_df_filepath = root_folder_filepath + r'first_name_results/infer_output_{0}_to_{1}.csv'.format(start_index, end_index - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b940b0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_names_openai_csv(source_df_filepath, output_df_filepath, start_index, end_index, first_name_only, include_country, rerun_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866e5ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate multiple CSV if needed\n",
    "merged_output_df_filepath = root_folder_filepath + r'first_name_results/olympic_openai_first_name_results.csv'\n",
    "cols = [index_col, name_col, output_col, gender_col, score_col]\n",
    "\n",
    "csv_filepaths = [\n",
    "    # Add CSV filepaths here\n",
    "]\n",
    "\n",
    "if len(csv_filepaths) != 0:\n",
    "    concatenate_csv(csv_filepaths, cols, raw_output_df_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a10e39a",
   "metadata": {},
   "source": [
    "## Full Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c0d34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index = 0\n",
    "end_index = 10000\n",
    "first_name_only = False\n",
    "include_country = False\n",
    "rerun_count = 0\n",
    "\n",
    "source_df_filepath = root_folder_filepath + r'source_olympic_data.csv'\n",
    "output_df_filepath = root_folder_filepath + r'full_name_results/infer_output_{0}_to_{1}.csv'.format(start_index, end_index - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6452dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_names_openai_csv(source_df_filepath, output_df_filepath, start_index, end_index, first_name_only, include_country, rerun_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def19d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate multiple CSV if needed\n",
    "merged_output_df_filepath = root_folder_filepath + r'full_name_results/olympic_openai_full_name_results.csv'\n",
    "cols = [index_col, name_col, output_col, gender_col, score_col]\n",
    "\n",
    "csv_filepaths = [\n",
    "    # Add CSV filepaths here\n",
    "]\n",
    "\n",
    "if len(csv_filepaths) != 0:\n",
    "    concatenate_csv(csv_filepaths, cols, raw_output_df_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ab208b",
   "metadata": {},
   "source": [
    "## First Name & Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46a04e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index = 0\n",
    "end_index = 10000\n",
    "first_name_only = True\n",
    "include_country = True\n",
    "rerun_count = 0\n",
    "\n",
    "source_df_filepath = root_folder_filepath + r'source_olympic_data.csv'\n",
    "output_df_filepath = root_folder_filepath + r'first_name_country_results/infer_output_{0}_to_{1}.csv'.format(start_index, end_index - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ad048d",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_names_openai_csv(source_df_filepath, output_df_filepath, start_index, end_index, first_name_only, include_country, rerun_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d0370f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate multiple CSV if needed\n",
    "merged_output_df_filepath = root_folder_filepath + r'first_name_country_results/olympic_openai_first_name_country_results.csv'\n",
    "cols = [index_col, name_col, country_col, output_col, gender_col, score_col]\n",
    "\n",
    "csv_filepaths = [\n",
    "    # Add CSV filepaths here\n",
    "]\n",
    "\n",
    "if len(csv_filepaths) != 0:\n",
    "    concatenate_csv(csv_filepaths, cols, raw_output_df_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e824666",
   "metadata": {},
   "source": [
    "## Full Name & Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43420286",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index = 0\n",
    "end_index = 10000\n",
    "first_name_only = False\n",
    "include_country = True\n",
    "rerun_count = 0\n",
    "\n",
    "source_df_filepath = root_folder_filepath + r'source_olympic_data.csv'\n",
    "output_df_filepath = root_folder_filepath + r'full_name_country_results/infer_output_{0}_to_{1}.csv'.format(start_index, end_index - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdc8e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_names_openai_csv(source_df_filepath, output_df_filepath, start_index, end_index, first_name_only, include_country, rerun_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c909964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate multiple CSV if needed\n",
    "merged_output_df_filepath = root_folder_filepath + r'full_name_country_results/olympic_openai_full_name_country_results.csv'\n",
    "cols = [index_col, name_col, country_col, output_col, gender_col, score_col]\n",
    "\n",
    "csv_filepaths = [\n",
    "    # Add CSV filepaths here\n",
    "]\n",
    "\n",
    "if len(csv_filepaths) != 0:\n",
    "    concatenate_csv(csv_filepaths, cols, raw_output_df_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c238bf",
   "metadata": {},
   "source": [
    "# Compile Final Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c9e8e6",
   "metadata": {},
   "source": [
    "The following function merges the results from the different test setups (first name vs. full name, no country vs. country) into a consistent table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30985295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filepath definitions\n",
    "source_olympic_df_filepath = root_folder_filepath + r'source_olympic_data.csv'\n",
    "first_name_df_filepath = root_folder_filepath + r'first_name_results/olympic_openai_first_name_results.csv'\n",
    "full_name_df_filepath = root_folder_filepath + r'full_name_results/olympic_openai_full_name_results.csv'\n",
    "first_name_country_df_filepath = root_folder_filepath + r'first_name_country_results/olympic_openai_first_name_country_results.csv'\n",
    "full_name_country_df_filepath = root_folder_filepath + r'full_name_country_results/olympic_openai_full_name_country_results.csv'\n",
    "\n",
    "# Load DataFrames\n",
    "source_olympic_df = pd.read_csv(source_olympic_df_filepath, usecols=[source_forename_col, source_surname_col, source_country_col, source_sex_col, source_medal_col])\n",
    "first_name_df = pd.read_csv(first_name_df_filepath, usecols=[index_col, name_col, gender_col, score_col])\n",
    "full_name_df = pd.read_csv(full_name_df_filepath, usecols=[index_col, name_col, gender_col, score_col])\n",
    "first_name_country_df = pd.read_csv(first_name_country_df_filepath, usecols=[index_col, name_col, country_col, gender_col, score_col])\n",
    "full_name_country_df = pd.read_csv(full_name_country_df_filepath, usecols=[index_col, name_col, country_col, gender_col, score_col])\n",
    "\n",
    "results_list = []\n",
    "\n",
    "for i in range(len(source_olympic_df)):\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "    \n",
    "    first_name = str(olympic_df.loc[i, source_forename_col]).title()\n",
    "    full_name = str(olympic_df.loc[i, source_forename_col]).title() + \" \" + str(olympic_df.loc[i, source_surname_col]).title()\n",
    "    country = str(olympic_df.loc[i, source_country_col]).split('-')[0].title()\n",
    "    actual_sex = str(olympic_df.loc[i, source_sex_col])\n",
    "    medal = str(olympic_df.loc[i, source_medal_col])\n",
    "    \n",
    "    # Use index to compare, assert that names are the same\n",
    "    first_name_row = first_name_df.loc[first_name_df[name_col] == first_name]\n",
    "    if first_name_row.empty:\n",
    "        first_name_gender = 'U'\n",
    "        first_name_score = '0'\n",
    "    else:\n",
    "        first_name_gender = first_name_row.iloc[0][gender_col]\n",
    "        first_name_score = first_name_row.iloc[0][score_col]\n",
    "    \n",
    "    full_name_row = full_name_df.loc[full_name_df[index_col] == i]\n",
    "    if full_name_row.empty:\n",
    "        full_name_gender = 'U'\n",
    "        full_name_score = '0'\n",
    "    else:\n",
    "        full_name_gender = full_name_row.iloc[0][gender_col]\n",
    "        full_name_score = full_name_row.iloc[0][score_col]\n",
    "        \n",
    "    first_name_country_row = first_name_country_df.loc[(first_name_country_df[name_col] == first_name) & (first_name_country_df['country'] == country)]\n",
    "    if first_name_country_row.empty:\n",
    "        first_name_country_gender = 'U'\n",
    "        first_name_country_score = '0'\n",
    "    else:\n",
    "        first_name_country_gender = first_name_country_row.iloc[0][gender_col]\n",
    "        first_name_country_score = first_name_country_row.iloc[0][score_col]\n",
    "        \n",
    "    full_name_country_row = full_name_country_df.loc[full_name_country_df[index_col] == i]\n",
    "    if full_name_country_row.empty:\n",
    "        full_name_country_gender = 'U'\n",
    "        full_name_country_score = '0'\n",
    "    else:\n",
    "        full_name_country_gender = full_name_country_row.iloc[0][gender_col]\n",
    "        full_name_country_score = full_name_country_row.iloc[0][score_col]\n",
    "    \n",
    "    # Index, Full Name, Country, Sex, First-Name Gender + Score, Full-Name Gender + Score, First-Name-Country Gender + Score, Full-Name-Country Gender + Score\n",
    "    results_list.append([i, full_name, country, medal, actual_sex, first_name_gender, first_name_score, full_name_gender, full_name_score, first_name_country_gender, first_name_country_score, full_name_country_gender, full_name_country_score])\n",
    "    \n",
    "output_df = pd.DataFrame(results_list, columns=['index', 'name', 'country', 'medal', 'sex', 'first_name_gender', 'first_name_score', 'full_name_gender', 'full_name_score', 'first_name_country_gender', 'first_name_country_score', 'full_name_country_gender', 'full_name_country_score'])\n",
    "output_df.to_csv((root_folder_filepath + r'final_results.csv'), index=False, header=True, encoding='utf-8-sig')\n",
    "print('Done')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
